{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf转txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = ''\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_path = 'data/rag/供电规则.pdf'  # Replace with your PDF file path\n",
    "text = extract_text_from_pdf(pdf_path).replace('\\n', '')\n",
    "# Save the extracted text to a file\n",
    "with open('data/extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#简单openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key='123',\n",
    "    base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    ")\n",
    "\n",
    "\n",
    "class AuthenticationError(Exception):\n",
    "    \"\"\"Custom exception for authentication errors.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def ask(question: str):\n",
    "    \"\"\"Ask a question to the model.\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model='qwen-max',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': '你是'},\n",
    "            {'role': 'user', 'content': question},\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = '请用一句话描述，{topic}。'\n",
    "prompt = PromptTemplate(input_variables=['topic'], template=template)\n",
    "\n",
    "formatted_prompt = prompt.format(topic='人工智能')\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(\n",
    "    model='qwen2.5:3b',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': '你是谁？',\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file('15.mp3')  # mp3或wav都可以\n",
    "\n",
    "\n",
    "def compute_correlation(audio_path):\n",
    "    # 1. 读取音频\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    if audio.channels != 2:\n",
    "        raise ValueError('音频不是立体声，无法比较左右声道。')\n",
    "\n",
    "    # 2. 拆分左右声道\n",
    "    left, right = audio.split_to_mono()\n",
    "\n",
    "    # 3. 把声道转成numpy数组（注意：raw_data是bytes）\n",
    "    samples_left = np.array(left.get_array_of_samples())\n",
    "    samples_right = np.array(right.get_array_of_samples())\n",
    "\n",
    "    # 4. 相关系数计算（归一化一下）\n",
    "    min_len = min(len(samples_left), len(samples_right))\n",
    "    samples_left = samples_left[:min_len]\n",
    "    samples_right = samples_right[:min_len]\n",
    "\n",
    "    correlation = np.corrcoef(samples_left, samples_right)[0, 1]\n",
    "\n",
    "    return correlation\n",
    "\n",
    "\n",
    "audio_path = 'data/record/audio/15.mp3'\n",
    "corr = compute_correlation(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_markdown_table(data):\n",
    "    if isinstance(data, list) and all(isinstance(d, dict) for d in data):\n",
    "        headers = list({key for d in data for key in d})\n",
    "        lines = ['| ' + ' | '.join(headers) + ' |']\n",
    "        lines.append('| ' + ' | '.join(['---'] * len(headers)) + ' |')\n",
    "        for row in data:\n",
    "            line = '| ' + ' | '.join(str(row.get(h, '')) for h in headers) + ' |'\n",
    "            lines.append(line)\n",
    "        return '\\n'.join(lines)\n",
    "    else:\n",
    "        raise ValueError('Only supports list of dicts for table conversion.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
